{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Load Packages](#packages)  \n",
    "2. [Goals](#goals)  \n",
    "3. [Data](#data)  \n",
    "4. [Early Data Analysis](#eda)   \n",
    "5. [Wrangling](#wrangling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Packages\n",
    "<a id=\"packages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sqlalchemy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe the goals of your study\n",
    "<a id=\"goals\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What factors were important in the survival of individuals who lived through the sinking of the titanic? Of those factors, did family, wealth, or gender figure into their ability to make it more than others?*  \n",
    "*As an aside, did boarding in France or Britain make any difference? If so, what were the additonal factors that made them liklier survivors?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aquire the Data\n",
    "<a id=\"data\"></a>\n",
    "1. [Connect](#connect)  \n",
    "2. [Query & Aggregate](#query)  \n",
    "3. [Risks & Assumptions](#risks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "# password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebozek/anaconda/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/Users/sebozek/anaconda/lib/python2.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Connect to the remote database\n",
    "<a id=\"connect\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Began by connecting to the database through terminal. Looked to see what tables were present **train** being the only table in the database*\n",
    "*Will test initially with just connecting to the database using sql magic. Then will continue through using sqlalchemy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Pclass</th>\n",
       "        <th>Survived</th>\n",
       "        <th>Sex</th>\n",
       "        <th>Age</th>\n",
       "        <th>SibSp</th>\n",
       "        <th>Parch</th>\n",
       "        <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>0</td>\n",
       "        <td>male</td>\n",
       "        <td>22.0</td>\n",
       "        <td>1.0</td>\n",
       "        <td>0</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "        <td>female</td>\n",
       "        <td>38.0</td>\n",
       "        <td>1.0</td>\n",
       "        <td>0</td>\n",
       "        <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>1</td>\n",
       "        <td>female</td>\n",
       "        <td>26.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "        <td>female</td>\n",
       "        <td>35.0</td>\n",
       "        <td>1.0</td>\n",
       "        <td>0</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>0</td>\n",
       "        <td>male</td>\n",
       "        <td>35.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(3L, 0L, u'male', 22.0, 1.0, 0L, u'S'),\n",
       " (1L, 1L, u'female', 38.0, 1.0, 0L, u'C'),\n",
       " (3L, 1L, u'female', 26.0, 0.0, 0L, u'S'),\n",
       " (1L, 1L, u'female', 35.0, 1.0, 0L, u'S'),\n",
       " (3L, 0L, u'male', 35.0, 0.0, 0L, u'S')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic\n",
    "\n",
    "SELECT \"Pclass\", \"Survived\", \n",
    "\"Sex\", \"Age\", \"SibSp\"::float, \"Parch\", \"Embarked\"\n",
    "FROM train\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "# Create engine for use with sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Query the database and aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT \"Pclass\", \"Survived\", \n",
    "\"Sex\", \"Age\", \"SibSp\"::float, \"Parch\", \"Embarked\"\n",
    "FROM train;\"\"\"\n",
    "\n",
    "train = pd.read_sql(sql, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived     Sex   Age  SibSp  Parch Embarked\n",
       "0       3         0    male  22.0    1.0      0        S\n",
       "1       1         1  female  38.0    1.0      0        C\n",
       "2       3         1  female  26.0    0.0      0        S\n",
       "3       1         1  female  35.0    1.0      0        S\n",
       "4       3         0    male  35.0    0.0      0        S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 What are the risks and assumptions of our data? \n",
    "<a id=\"risks\"></a>\n",
    "\n",
    "One of the risks of the data is that those who did not survive may have survived the sinking of the Titanic, but died of exposure on the lifeboat. \n",
    "The data relies on the proper preservation of the records related to the sinking of the titanic. Handwriting can be difficult to read, so assuming that all of it was properly converted from handwriting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Exploratory Data Analysis\n",
    "<a id=\"eda\"></a>\n",
    "1 [Description And Dictionary](#dict)  \n",
    "2 [Visualization](#viz) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Describe the Data\n",
    "<a id=\"dict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass    Survived         Age       SibSp       Parch\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000\n",
       "mean     2.308642    0.383838   29.699118    0.523008    0.381594\n",
       "std      0.836071    0.486592   14.526497    1.102743    0.806057\n",
       "min      1.000000    0.000000    0.420000    0.000000    0.000000\n",
       "25%      2.000000    0.000000   20.125000    0.000000    0.000000\n",
       "50%      3.000000    0.000000   28.000000    0.000000    0.000000\n",
       "75%      3.000000    1.000000   38.000000    1.000000    0.000000\n",
       "max      3.000000    1.000000   80.000000    8.000000    6.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Name|Description|Variable Type|\n",
    "|--|--|--|\n",
    "|PClass|The class of ticket purchase|Ordinal|\n",
    "|Survived|Whether or not the Individual Survived|Target(Categorical)|\n",
    "|Age|Age of the Individual|Nominal|\n",
    "|SibSp|Number of Siblings and Spouse|Nominal|\n",
    "|Parch|Number of Parents and Children|Nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First issue found is that age has 97 fewer counts than the other categories present. Likely filled with many null values*\n",
    "\n",
    "*Since age is important to one of the questions asked the intial data explored will be only including those with ages. Another analysis will be done with no regard for age to see how much the models change.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Age.isnull().value_counts()\n",
    "\n",
    "train_na = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the Data\n",
    "<a id=\"viz\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x11806b210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAIVCAYAAABiEd1DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3X2cnWV94P9PHgghDDOoeSRPQ6h821JqXfNACA/y9Ivy\n0Got62q1Bmtr1bVWLbtCt3a1W3SrZe22a0WpIlpdrZZWbUCQFYQoiagoAn6jBAKEhASQCWN4SmZ+\nf5yTZDLJzJwz5z7n3Cf5vF8vXsx1zjXf6zvnvubkO9d9n/uaMDg4iCRJUlEmtjsBSZJ0cLG4kCRJ\nhbK4kCRJhbK4kCRJhbK4kCRJhbK4kCRJhZrcroEjYhnwwcw8Y9jjrwHeATwH3JmZb21HfpIkaXza\nsnIRERcDnwAOH/b4VOD9wOmZeSpwdESc34YUJUnSOLXrtMjPgFce4PFngJMz85lqezLwdMuykiRJ\nDZvQrjt0RsRC4POZefIIz78deFlmnjdGnMnAPOChzNxZfKbS+Dg3VVbOTTVb2665GElETAD+Gngh\n8Ns1fMs84L4bb7yxqXnpoDShyfGdmxov56bKqqa52e7i4kBJfhx4KjNf0epkJElS49pdXAzCnk+I\nHAl8D7gIuCUivll9/m8z89/al6IkSapH24qLzNwInFz9+vNDnmp3wSNJkhrgTbQkSVKhLC4kSVKh\nLC4kSVKhLC4kSVKhLC4kSVKhLC4kSVKhLC4kSVKhLC4kSVKhLC4kSVKhLC4kSVKhLC4kSVKhLC4k\nSVKhLC4kSVKh2lZcRMSy6rbqwx+/ICLWRcSaiHhTO3KTJEnj15biIiIuBj4BHD7s8cnA5cDZwEuB\nP4yIGS1PUJIkjdvkNo37M+CVwGeGPf4rwE8zcztARNwKnAZ8ubXpSeX2wAN9rF3/CJse7WfujC6W\nLZ7Fgp6ewvpvffRJbr5j857+Zyyew/Seow7Y9xdP72T1mg1s2tbP/BldnLdiEVOnjvzW8tSzu1i9\nZgMPbe1nwcxK/ylTJtX+w6sU6p1TnRCnbHNz18Ag6+7awsbNffTO6WHpCbOZOHFC2/KpR1uKi8y8\nJiIWHuCpbqBvSPtJoP5ZJh3k1q5/hKuvvWfvA4Ow4OyRf1Xq7X/zHZv363/h2QcuLlav2cDVq/f2\nHQAuPOv4EWOvXrOBq7529z79X3XGC0fsr3Kqd051Qpyyzc11d23hsqvW7Wlfumopy0+c07Z86lG2\nCzq3UykwdjsKeKJNuUiltenR/lHbrey/aVv/qO3hHtraP2pbnaHeOdUJcco2Nzdu7hu1XWbtOi2y\n2/D1nXuAX4qIo4EdVE6JfKjlWUklN3dG177t6V0j9Gx+//nD+84YPfaCmfs+P2/m6P1VTvXOqU6I\nU7a52Ttn35WXhXM6ZyG/3cXFIEBEvAY4MjOvjIh3AddTKTyuzMzN7UxQKqNli2fBYOWvs7nTu1i2\nZFah/c9YPGef/mcsGXkp9rwVixigsmIxd0YXF6xYNGrs3f0f2trPvJlj91c51TunOiFO2ebm0hNm\nc+mqpWzc3MfCOT0sO2F2W/Opx4TBwcF259CQiOgF7rvxxhuZN29eu9NRZ2nqlVHOTTXAuamyqmlu\nlu2aC0mS1OEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqHafZ+LUrr+xpt5ePMjY/Y7duF8\nTj91eQsykiSpc1hcHMCXvv4DNu86dsx+vT/5nsWFJEnDeFpEkiQVyuJCkiQVyuJCkiQVyuJCkiQV\nyuJCkiQVyuJCkiQVquUfRY2ICcBHgRcBTwNvyswNQ57/XeBdwE7gU5n5sVbnKEmSxq8dKxevAA7P\nzJOBS4DLhz3/IeBM4BTg3RHR0+L8JElSA9pRXJwCXAeQmWuBxcOe/yHwPOCIanuwdalJkqRGtaO4\n6Ab6hrR3RsTQPO4CvgfcCXwtM7e3MjlJktSYdhQX24GjhuaQmQMAEXEicB6wEOgFZkXEq1qeoSRJ\nGrd2FBdrgHMBIuIkKisUu/UBO4BnMnMQ2ErlFIkkSeoQ7di47BrgnIhYU21fFBGvAY7MzCsj4uPA\nrRHxDHAvcFUbcpQkSePU8uKiuiLxlmEPrx/y/BXAFS1NSpIkFcabaEmSpEJZXEiSpEJZXEiSpEJZ\nXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEKNehOtiDhttOcz81vFpiNJkjrdWHfofF/1/y8A\nfonKviC7gJOp7AmyonmpSZKkTjRqcZGZZwBExGrgtzPzZ9X2QrxFtyRJOoBar7lYuLuwqHqAyrbo\nkiRJ+6h147LvRcSngS9SKUheC9zStKwkSVLHqrW4eBPwduCPgEHgG8BHxzNgREyofu+LgKeBN2Xm\nhiHPLwH+ptrcArwuM58dz1iSJKn1ajotUv3H/cvAx4DfBr6amTvHOeYrgMMz82TgEuDyYc9/HFiV\nmacB1+HpF0mSOkpNxUVEvBr4KvC3wPOB70TE68Y55ilUigYycy2weMg4xwOPAe+KiJuA52fmT8c5\njiRJaoNaL+j8r1Q+fvpkZm4FXkxl1WE8uoG+Ie2dEbE7j+nAcuB/A2cDZ0fES8c5jiRJaoNai4td\nmfnk7kZmbgYGxjnmduCooTlk5u5YjwE/y8z11dMu1zFkZUOSJJVfrcXFXRHxn4HDIuI3IuLjwB3j\nHHMNcC5ARJxE5WZcu20AuiJiUbV9KnDXOMeRJEltUGtx8TZgLvAU8Ekqqw9vHeeY1wDPRMQaKp8K\neWdEvCYi3pSZzwG/D3w+ItYCD2TmteMcR5IktUGtH0X9A+AjmTne6yz2yMxB4C3DHl4/5PmbgGWN\njiNJktqj1uJiLnBbRCTwWeBfMnNH89KSJEmdqtb7XFycmccCfwWcBNwREZ9pamaSJKkj1XrNxe47\nax4GTKHySZFnmpWUJEnqXDWdFomIv6NyZ80fAP8E/HFmPt3MxCRJUmeq9ZqL9cB/yMxtzUxGkiR1\nvlGLi4j4w8z8OJVbfr8lIvZ5PjPf38TcJElSBxpr5WLCCF9LkiQd0KjFRWZeUf2yD/h8Zj7S/JR0\nKNm1axf33ntvTX2PO+44Jk2a1OSMJEmN8j4Xaqt7772X11/yOab1zBy1346+rXzmA6/l+OOPb1Fm\nkqTxqqm4yMyLgYsj4lTg1cB7I2JtZr6+qdnpkDCtZyZdz5vb7jQkSQXxPheSJKlQ9dzn4reo7IT6\nWbzPhSRJGkGt11w8ArzE+1xIkqSx1Fpc/G5m/o8iBqyeXvko8CLgaeBNmbnhAP2uAB7LzEuLGFeS\nJLVGrcXF3RHxXmAt8NTuBzPzW+MY8xXA4Zl5ckQsAy6vPrZHRLwZ+DXg5nHElyRJbVRrcfF84Izq\nf7sNAmeOY8xTgOsAMnNtRCwe+mRELAeWAFcAvzyO+JIkqY1q/SjqGWP3qlk3lZty7bYzIiZm5kBE\nzAb+gspKxqsLHFOSJLVIrZ8W+SaVlYp9ZOZ4Vi62A0cNaU/MzIHq1xcCLwBWA3OAIyLiJ5l59TjG\nkSRJbVDraZH/PuTrw6h8LPXn4xxzDXA+8KWIOAm4c/cTmfl3wN8BRMQbgLCwkCSps9R6WmT4hZXf\niIi1wHvHMeY1wDkRsabavigiXgMcmZlXjiOeJEkqkVpPiywY0pwAnEDl9EXdMnMQeMuwh9cfoN+n\nxxNfkiS1V62nRW5m7zUXg8CjwNubkpEkSepoY+4tEhHnA2dn5iLg3cA9wNeBG5qcmyRJ6kCjFhcR\n8adUPhp6eET8OpV9Rf4V6AI+3Pz0JElSpxlr5eL1wOmZeTfwWuAr1Ysu3w2sbHZykiSp84xVXAxm\n5o7q12ew986a+93zQpIkCca+oHNnRBxN5TTIi4HrASJiIbCzyblJkqQONNbKxQeBO4DbgCszc3NE\n/EfgRuCvm52cJEnqPKOuXGTmlyLi28D0zPxR9eF+Ktuk39Ts5CRJUucZ8z4Xmfkw8PCQ9uqmZiRJ\nkjramPe5kCRJqofFhSRJKpTFhSRJKpTFhSRJKlStG5cVJiImAB8FXgQ8TeWTJxuGPP8a4B3Ac8Cd\nmfnWVucoSZLGrx0rF68ADs/Mk4FLgMt3PxERU4H3U7nl+KnA0dWN0yRJUodoR3FxCntvI74WWDzk\nuWeAkzPzmWp7MpXVDUmS1CHaUVx0A31D2jsjYiJU9izJzG0AEfF24MjM/EYbcpQkSePU8msugO3A\nUUPaEzNzYHejek3GXwMvBH67xblJkqQGtaO4WAOcD3wpIk4C7hz2/MeBpzLzFS3PTJIkNawdxcU1\nwDkRsabavqj6CZEjge8BFwG3RMQ3gUHgbzPz39qQpyRJGoeWFxeZOQi8ZdjD64d83Y6CR5IkFcSb\naEmSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiS\npEJZXEiSpEJZXEiSpEJZXEiSpEK1fAfSiJgAfBR4EfA08KbM3DDk+QuAPweeAz6VmVe2OkdJkjR+\n7Vi5eAVweGaeDFwCXL77iYiYXG2fDbwU+MOImNGGHCVJ0ji1fOUCOAW4DiAz10bE4iHP/Qrw08zc\nDhARtwKnAV9ueZZSiT3wQB9r1z/Cpkf7mTuji2WLZ7Ggp6ew/lu29nHLj/b2P33xLGaO0H/bY/3c\n9IOH9/Q9c/ExvKCnq5DYAE/ueI7rvn0fmx7tZ96MLs5dfizTph02Yv9me2L7M9ywbuOe/FcuWUh3\n9+Fty6dd6p1TnRDn2Z0DXH/b/Wzcsp3eOd2sXNbL5Mn1/w3+i6d3snrNBjZt62f+jC7OW7GIqVPr\n/+e2qDi7BgZZd9cWNm7uo3dOD0tPmM3EiRPqjlOPdhQX3UDfkPbOiJiYmQMHeO5JoP5ZJh3k1q5/\nhKuvvWfvA4Ow4OyRf1Xq7X/Lj/bvf+EI/W/6wcMH6Ht8IbEBrvv2ffv0HxwjfrPdsG5jXT/vware\nOdUJca6/7X6uuObOvSEG4fxTFtWdy+o1G7h69d5cBoALz6p/jhQVZ91dW7jsqnV72peuWsryE+fU\nHace7Tgtsh04amgO1cJi93PdQ547CniiVYlJnWLTo/2jtlvZv0y5tELZ8mmXol6HMsXZuGX7qO2a\nc9nWP2q71XE2bu4btd0M7Sgu1gDnAkTEScCdQ567B/iliDg6IqZQOSXyndanKJXb3Bn7nnaYO33k\n0xDN7t/sXObV2b/Z6s3/YFXU61CmOL1zuvdpL5zdPULP0c0fnsuM8f1MRcXpnbPvCs7COc0/IdCO\n0yLXAOdExJpq+6KIeA1wZGZeGRHvAq4HJgBXZubmNuQoldqyxbNgsPLX2dzpXSxbMqvQ/qcP63/6\nKP3PXHzMPn3PXHJMYbEBzl1+LIND+p938rGj9m+2lUsW7pP/yqUL25pPu9Q7pzohzsplvQwOVlYs\nFs7u5mUn9Y4rl/NWLGKAykrD3BldXLCi/lMrRcZZesJsLl21lI2b+1g4p4dlJ8weV5x6TBgcHGz6\nIM0UEb3AfTfeeCPz5s0rJOYf/pePsHnX2G9gvUc8yN/9j/9cyJiHqvXr1/PmD36DrufNHbVf/883\nccV7zub44ws9t93UK5qaMTd1yHBuqqxqmpveREuSJBXK4kKSJBXK4kKSJBXK4kKSJBXK4kKSJBXK\n4kKSJBXK4kKSJBXK4kKSJBXK4kKSJBXK4kKSJBXK4kKSJBXK4kKSJBXK4kKSJBWq5VuuR8RU4LPA\nTGA78IbMfGxYn3cCrwYGgdWZ+ZetzlOSJI1PO1Yu3gL8KDNPAz4D/PnQJyPiWOA1mXlSZi4HVkbE\nr7UhT0mSNA7tKC5OAa6rfn0tcPaw5x8AXjakfRjwdAvykiRJBWjqaZGIeCPwTiqnNwAmAFuAvmr7\nSaB76Pdk5i7g8er3fwj4fmb+bJRhJgFs2bKlsLx//tg2+genjNnviace5Vvf+lZh4x6KHnzwQXb0\nbR2z346+rWzZsoVp06YVNvZZZ53VCzyUmTsLC7qvwuemDg3OTZVVrXNzwuDg4GjPFy4ivgx8IDNv\nj4hu4NbM/PVhfQ4HPkmlCHlbZo6YZEScAtzSzJx1UDs2M+9vRmDnphrk3FRZjTk3W35BJ7AGOBe4\nvfr/A03wrwDfyMwP1RDvu8CpwGZgV1FJ6pDxUBNjOzfVCOemymrMudmOlYsjgE8Dc4BngNdm5tbq\nJ0R+SqXg+RxwG5XTKIPAJZm5tqWJSpKkcWl5cSFJkg5u3kRLkiQVyuJCkiQVyuJCkiQVyuJCkiQV\nyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVqh1bru8nIpYB\nH8zMMyLiOOAqYAD4cWa+ra3JSZKkurR95SIiLgY+ARxefehy4NLMPB2YGBG/1bbkJElS3dpeXAA/\nA145pP2SzLyl+vW1wNmtT0mSJI1X20+LZOY1EbFwyEMThnz9JNAz2vdHxGRgHvBQZu5sQorSuDg3\nVVbOTTVb24uLAxgY8vVRwBNj9J8H3HfjjTc2LyMdrCaM3aUhzk2Nl3NTZVXT3CzDaZHhvh8Rp1W/\nfjlwy2idJUlSuZRx5eJPgU9ExGHAPcCX2pyPJEmqQymKi8zcCJxc/fqnwEvbmpAkSRq3Mp4WkSRJ\nHcziQpIkFcriQpIkFcriQpIkFcriQpIkFcriQpIkFcriQpIkFcriQpIkFcriQpIkFcriQpIkFcri\nQpIkFcriQpIkFcriQpIkFcriQpIkFcriQpIkFWpyuxOQND5fuubf+eINPx6z3+kvnsfb/uB3W5CR\nJFVYXEgdqu/Jfp464pfH7LfjmSdakI0k7VXK4iIiJgOfBnqBncAfZOb6tiYlSZJqUsriAjgXmJSZ\nKyLibOAy4HeaPegT25/hhnUb2fRoP3NndLFyyUK6uw9v9rCSpAb5/l0uZS0u1gOTI2IC0AM824pB\nb1i3kauvvWfvA4Nw4dnHt2JoSVIDfP8ul7IWF/3AscBPgBcA57di0E2P9o/aliSVk+/f5VLWj6K+\nE7guMwN4EXB1RExp9qBzZ3Tt257eNUJPSVKZ+P5dLmVduXgceK769RNU8pzU7EFXLlkIg5WKd+70\nLlYuXdjsISVJBfD9u1zKWlx8BPhkRHwLOAy4JDOfavag3d2He45OkjqQ79/lUsriIjN/Aby63XlI\nkqT6lfWaC0mS1KEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJ\nUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEmtzuBkUTEe4DfBA4D\nPpqZn2pzSpIkqQalXLmIiNOB5Zl5MvBSYH57M5IkSbUq68rFSuDHEfGvwFHAxW3OR5Ik1aisxcV0\nYAFwPrAI+Arwy23NSJIk1aSUp0WAx4CvZ+bOzFwPPB0R09udlCRJGltZi4tbgZcBRMQxwDQqBYck\nSSq5UhYXmfnvwA8iYh3wb8BbM3OwzWlJkqQalPWaCzLzPe3OQZIk1a+UKxeSJKlzWVxIkqRCWVxI\nkqRCWVxIkqRCWVxIkqRCWVxIkqRCWVxIkqRClfY+F+3w5I7nuO7b97Hp0X7mzeji3OXHMm3aYe1O\nS5I0Bt+/y6Ww4iIiJgO/DuwE7uzEO2pe9+37uPrae/a0BwfhwrOPb2NGkqRa+P5dLoWcFomIc4AH\ngI8DnwY2RMSSImK30qZH+0dtS5LKyffvcilq5eJ/AS/PzB8CRMRi4GPA4oLit8S8GV37tOdO7xqh\npySpTHz/LpeiiotndhcWAJl5e0RMKCh2y5y7/FgGBysV79zpXZx38rHtTkmSVAPfv8ulqOJibURc\nCXyCyjUX/wm4PyJOA8jMbxU0TlNNm3aY5+gkqQP5/l0uRRUXv1L9/weHPf4+YBA4s6BxJElSyRVS\nXGTmGUXEkSRJna+h4iIiJgJvBW7KzB9HxB8DfwB8H3h7Zm4vIEdJktRBGv0o6geAc4D+iFgB/CXw\nTirFxf9uMLYkSepAjZ4WORd4cWbujIg/Ab6Umd8AvhER94zxvWOKiJnA7cDZmbm+0XiSJKn5Gl25\n2JWZO6tfvxS4vqjY1Tt+fgzY0UgcSZLUWo2uXOyIiAXAUVQ+MXIDQET8OtDo9RYfBv4BuKTBODXb\nsrWPW370SOVz0jO6OH3xLGb29LRqeI3gqWd3sXrNBh7a2s+CmV2ct2IRU6ZMandakgrw+BNPcePt\nD+553z1n8XyO7jmibXFUjEaLi0uB7wDdwPsy8/GIeAvwF8Cq8QaNiFXA1sy8ISIubTDHmt3yo0f2\nuTc9g3Dh2RYX7bZ6zQau+trde9oDwKvOeGH7EpJUmBtvf/AA77v136+iqDgqRkOnLjLzJuBYYH5m\nXlZ9+PvAqZl5XQOhLwLOiYhvAr8BXF29/qKpvDd9OT20tX/UtqTOVdT7ru/f5dLwfS4y81ng2Yi4\ngMp1F88B3wB+2kDM03d/XS0w3pyZWxtMdUxzvTd9KS2Yue9xmDfT4yIdLIp63/X9u1wKuYlWRHwA\nOAX4IjAB+MuIWJKZHyggfMu2bj998SwYcm/605fMatXQGsV5KxYxQGXFYt7MLi5YsajdKUkqyDmL\n5+/zvnvOkvltjaNiFHX77/OpfiQVICI+TuUjpA0XF5nZsluHz+zp8RqLEpoyZZLXWEgHqaN7jijk\n2oii4qgYjX4UdbfHqVzUudsUoK+g2JIkqYM0evvvT1E5bTER+GFEfIXKrqjnAj9pPD1JktRpGj0t\nclP1/zcPe/z7DcaVJEkdqtHi4uuZuaV6Iy1JkqSGi4srqVzMeTMH/lSHl/VLknSIafQmWudHxPlU\nNhZbBLwbuBv4LBAF5CdJkjpMoxd0vhv4T8AbqvuJfBZ4B/CrwF9T2X69Y2x7rJ+bfvDwnnvTn7n4\nGF7Q441Y2u0XT+9k9ZoNbNrWz/wZlb1Fpk4t6lPUksbj2Z0DXH/b/Wzcsp3eOd2sXNbL5Mn1/736\nxPZnuGHdxj3vuyuXLKS7+/C2xVExGn2H/j1geWbuiIgPAl/JzCsjYgKVFYyOKi5u+sHD3pu+hFav\n2cDVq/celwHgwrM8LlI7XX/b/VxxzZ172oODcP4p9Z8Jv2HdxkLed4uKo2I0ep+LwczcvSX6GcB1\nAJnZsrtqFsl705fTpm39o7Yltd7GLdtHbdfKvUUOTo2uXOyMiKOBLuDFwPUAEbGQyv0uOor3pi+n\n+cOPywyPi9RuvXO692kvnN09Qs/RubfIwanR4uKDwB3VOFdm5uaI+I/AZcD7Gk2u1c5cfMw+96Y/\nc8kx7U5J7N1bZNO2yrlU9xaR2m/lsl4GBysrFgtnd/Oyk3rHF2fJwn3ed1cuXdjWOCpGQ8VFZn4p\nIr4NTM/MH1Uf7gfeVN2OvaO8oKfLc3QlNHXqZK+xkEpm8uSJ47rGYrju7sMLed8tKo6KUcSW6w8D\nDw9pr240piRJ6lxFbVwmSZIEWFxIkqSCWVxIkqRCWVxIkqRClfIeyhExGfgk0AtMAf4qM7/a1qQk\nSVJNyrpy8Trg0cw8DXg58PdtzkeSJNWolCsXwBeBf65+PRF4rhWDbtnaxy0/emTPxjenL57FzJ6e\nVgytUWx99EluvmPznuNyxuI5TO85qt1pSYe0zY/0ceude98vT1s8i1njeL8sasOxIjY43DUwyLq7\ntrBxcx+9c3pYesJsJk6cUHcuKmlxsXu/kog4ikqR8WetGPeWHz1ygI1vLC7a7eY7Nh/guFhcSO10\n653FvF8WteFYERscrrtrC5ddtW5P+9JVS1l+4py6c1F5T4sQEfOB/wd8OjO/0Iox3fimnDwuUvmU\nbcOxIjY43Li5b9S2alfKlYuImAV8HXhbZn6zVeO68U05eVyk8inbhmNFbHDYO2fflZeFc1y5Hq9S\nFhfAJcDRwJ9HxHuBQeDlmflMMwc9ffGsfTa+OX3JrGYOpxqdsXjOPsfljCUuU0rtdtqw98vTxvl+\nWdSGY0VscLj0hNlcumopGzf3sXBOD8tOmD2uXFTS4iIz/wT4k1aPO7Onx2ssSmh6z1FeYyGVzKyC\n3i+L2nCsiA0OJ06cwPIT53idRQFKWVxIKsbgwC62bd3C+vXrx+x73HHHMWnSpBZkJelgZ3EhHcR+\n0beFmx94iu9+8Buj9tvRt5XPfOC1HH+8W1ZLapzFhXSQm9Yzk67nzW13GpIOIaX9KKokSepMFheS\nJKlQFheSJKlQXnMxxAMP9LF2/d575S9bPIsF7i3Sdh4XqXyK+r0sKs5DD/fxnbv3xlmxeBbH1Bnn\nqWd3sXrNBh7a2s+CmZX9SaZMqf8TVGWL0449Uywuhli7fv975S/wvhdt53GRyqeo38ui4nzn7sb3\nOlm9ZgNXfe3uPe0B4FVnvLDuXMoWpx17pnhaZAj3sCgnj4tUPqXbW6SAOA9t7R+13alx2rFnisXF\nEO5hUU4eF6l8yra3SBFxFszc93vmzRxfLmWL0449UzwtMsSyYffKX+beIqXgcZHKp6jfy6LirBgW\nZ8U44uzen+Shrf3Mmzm+/UnKGKcde6ZYXAyxoKfHc/kl5HGRyqeo38ui4hxTwF4nU6ZMGtc1DWWP\n0449UzwtIkmSCmVxIUmSCmVxIUmSCmVxIUmSCmVxIUmSClXKT4tExATgo8CLgKeBN2XmhvZmJUmS\nalHK4gJ4BXB4Zp4cEcuAy6uPNZV7WJSTx0Uqn7LtLVJEnKL24CgqzrM7B7j+tvvZuGU7vXO6Wbms\nl8mTO+OEQ1mLi1OA6wAyc21ELG7FoO5hUU4eF6l8yra3SBFxitqDo6g41992P1dcc+ee9uAgnH/K\n+G6k1WplLYG6gaE3P98ZEU3P1T0sysnjIpVPmfYEKSpOUXtwFBZny/ZR22VW1uJiO3DUkPbEzBxo\n9qDuYVFOHhepfMq0J0hRcYrag6O4ON37xpndPULP8inraZE1wPnAlyLiJODOMfoXwj0sysnjIpVP\n2fYWKSJOUXtwFBVn5bJeBgcrKxYLZ3fzspN6xxWnHcpaXFwDnBMRa6rti1oxqHtYlJPHRSqfsu0t\nUkScovbreL8EAAAgAElEQVTgKCrO5MkTO+Yai+FKWVxk5iDwlnbnIUmS6lfWay4kSVKHsriQJEmF\nsriQJEmFsriQJEmFsriQJEmFsriQJEmFsriQJEmFsriQJEmFsriQJEmFsriQJEmFsriQJEmFsriQ\nJEmFsriQJEmFKuWuqJJaa3BggPvuu2/MfscddxyTJk1qQUaSOpnFhSSeenIb7/34o0zruXfEPjv6\ntvKZD7yW448/voWZSepEFheSAJjWM5Ou581tyVi7du3i3ntHLmSGcrVE6jylKy4iohv4LNANHAa8\nOzNva29Wkmo9dQJjFwT33nsvr7/kc0zrmTlqHFdLpM5UuuICeBfwjcz83xFxPPB54CVtzkk65NVy\n6gRqLwhauVJSK1dUpGKUsbi4HHim+vVhwFNtzEXSEK0uCFp9oakrKlIx2lpcRMQbgXcCg8CE6v8v\nyszvRcRs4DPAH48RZhLAli1bmpmqDkJnnXVWL/BQZu5s0hBNnZvb+57g6W0/H7XPM9u3sWvSUWPG\neurJx6n8CjbWByr/8H73u98d9ed+8MEH2dG3dcxYjz+cXPzhu5na9fwR+zzd/zj/ddUK5s+fP2a8\nsTz44IM1992yZQvTpk1reMwD6fS5qYNXrXNzwuDgYGsyqkNEnAh8jsr1FteP0fcU4JaWJKaD0bGZ\neX8zAjs31SDnpspqzLlZutMiEfGrwBeB/5iZd9bwLd8FTgU2A7uamZsOSg81MbZzU41wbqqsxpyb\npVu5iIh/BX4duJ/KGuwTmfnKtiYlSZJqVrriQpIkdTb3FpEkSYWyuJAkSYWyuJAkSYWyuJAkSYWy\nuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYUq3ZbrABHxBmAV\nMAgcAbwImJ2Z29uZlyRJGlvpd0WNiL8HfpCZ/9juXCRJ0thKfVokIhYDv2phIUlS5yjlaZEhLgHe\nN1qHiJgMzAMeysydLclKqoFzU2Xl3FSzlba4iIge4PjMvHmMrvOA+2688cYWZKWDzIQmx3duaryc\nmyqrmuZmmU+LnAY48yVJ6jBlLi4C2NDuJCRJUn1Ke1okMz/c7hwkSVL9SltcSJLK7Z6frOf9f/sF\njjiia8y+R0/bxeX/409bkJXKwOJCkjQu25/czrZdczhiwowx+058+r4WZKSyKPM1F5IkqQNZXEiS\npEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEJZXEiSpEKV9g6dEfEe4DeBw4CP\nZuan2pySJEmqQSlXLiLidGB5Zp4MvBSY34pxdw0M8p07N/N/r/8Jt925mYGBwVYMKzWdc1tSK5V1\n5WIl8OOI+FfgKODiVgy67q4tXHbVuj3tS1ctZfmJc1oxtNRUzm1JrVTKlQtgOvAS4HeAtwCfa8Wg\nGzf3jdqWOpVzW1IrlbW4eAz4embuzMz1wNMRMb3Zg/bO6dmnvXBYW+pUzm1JrVTW0yK3An8M/K+I\nOAaYRqXgaKqlJ8zm0lVL2bi5j4Vzelh2wuxmDym1hHNbUiuVsrjIzH+PiFMjYh0wAXhrZjb9CrSJ\nEyew/MQ5novWQce5LamVSllcAGTme9qdgyRJql9Zr7mQJEkdyuJCkiQVyuJCkiQVyuJCkiQVyuJC\nkiQVyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVyuJCkiQVqrS3/46I7wG794W+LzN/v535SJKk2pSy\nuIiIwwEy88x25yJJkupTyuICeBFwZER8HZgE/Flmrm32oL94eier12xg07Z+5s/o4rwVi5g6tawv\n0aFj18Ag6+7awsbNffTO6WHpCbOZOHFCu9Nqq2d3DnD9bfezcct2eud0s3JZL5Mnj3yW86lnd7F6\nzQYe2trPgpmVuT1lyqQWZizpUFLWfzl3AB/KzH+MiBcC10bE8Zk50MxBV6/ZwNWr79nTHgAuPOv4\nZg6pGqy7awuXXbVuT/vSVUsP+a3Dr7/tfq645s497cFBOP+URSP2X71mA1d97e497QHgVWe8sJkp\nSjqElfWCzvXAPwFk5k+Bx4Cm/2uyaVv/qG21x8bNfaO2D0Ubt2wftT3cQ1v7R21LUpHKWly8Efgb\ngIg4BjgK2NzsQefP6NqnPXdYW+3RO6dnn/bCYe1DUe+c7n3aC2d3j9CzYsHMfefyvJnObUnNU9bT\nIv8IfCoibqGygvvGZp8SAThvxSIGqKxYzJ3RxQUrRl5mVussPWE2l65aysbNfSyc08OyE2a3O6W2\nW7msl8HByorFwtndvOyk3lH7757bD23tZ95M57ak5iplcZGZzwGva/W4U6dO9hqLEpo4cQLLT5xz\nyF9nMdTkyRNHvcZiuClTJnmNhaSWKetpEUmS1KEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJ\nUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqEsLiRJUqFKubfIbhExE7gdODsz17c7H0mSNLbSFhcR\nMRn4GLCjVWP+4umdrF6zgU3b+pk/o4vzVixi6tTSvkQ6hO0aGGTdXVvYuLmP3jk9LD1hNhMnThix\n/1PP7mL1mg08tLWfBTMrc3vKlEktzFjSoaTM/3J+GPgH4JJWDbh6zQauXn3PnvYAuEuqSmndXVu4\n7Kp1e9qXrlo66q6xq9ds4Kqv3b2nPQDukiqpaUp5zUVErAK2ZuYNwMh/jhVs07b+UdtSWWzc3Ddq\ne7iHtvaP2pakIpWyuAAuAs6JiG8CvwFcXb3+oqnmz+japz13WFsqi945Pfu0Fw5rD7dg5r5zed5M\n57ak5inlaZHMPH3319UC482ZubXZ4563YhEDVFYs5s7o4oIVi5o9pDQuS0+YzaWrlrJxcx8L5/Sw\n7ITZo/bfPbcf2trPvJnObUnNVcriYpjBVg00depkr7FQR5g4cQLLT5wz6nUWQ02ZMslrLCS1TOmL\ni8w8s905SJKk2pX1mgtJktShLC4kSVKhCjstEhFHAs9nyEdHM/OBouJLkqTOUEhxERF/AVwMbBvy\n8CDgJemSJB1iilq5WAUszMzHCoonSZI6VFHXXDwMjH6LQEmSdEhoaOUiIt5b/fIJ4DsRcS2wc/fz\nmfn+RuJLkqTO0+hpkd0Xb647wGOSJOkQ1FBxkZnvgz3bo5+bmV+JiOnAbwKfKiA/SZLUYYq65uLj\nwKuGtM+gsl26JEk6xBT1aZElmXkiQGY+Crw+In403mARMRH4BBDAAPBHmXl3IZlKkqSmKmrlYmJE\n7NlBqbo9+kAD8S4ABjPzFODPgcsazE+SJLVIUSsXfwX8ICJupXJB51LgHeMNlpn/FhFfrTZ7gZ83\nnGENnt05wPW33c/GLdvpndPNymW9TJ7sHdLb7alnd7F6zQYe2trPgpldnLdiEVOmTGp3Wm21a2CQ\ndXdtYePmPnrn9LD0hNlMnDjytdT1vob1xpekoYoqLn4M/AdgOfAc8J8zc3MjATNzICKuAl4B/E7D\nGdbg+tvu54pr7tzTHhyE80/xJqPttnrNBq762t6zYgNwyG8fvu6uLVx21d4PaV26aumo26/X+xrW\nG1+Shirqz/IvZObDmfnlzPxKo4XFbpm5CjgeuDIijigi5mg2btk+alvt8dDW/lHbh6KNm/tGbQ9X\n72tYb3xJGqqolYu7qzfUWgs8tfvBzPzWeIJFxOuAeZn5QeBpYBeNXcNRk9453fu0F87uHqGnWmnB\nzK592vOGtQ9FvXN69mkvHNYert7XsN74kjRUUcXF86l8/PSMIY8NAmeOM96/AJ+KiJup5PiOzHym\nsRTHtnJZL4ODlRWLhbO7edlJvc0eUjU4b8UiBqj8tT1vZhcXrPBU1dITZnPpqqVs3NzHwjk9LDth\n9qj9630N640vSUMVUlxk5hlj96or3g7g1UXGrMXkyRO9xqKEpkyZdMhfYzHcxIkTWH7inJqvg6j3\nNaw3viQNVdSW66dQ2XK9i8qnRSZR2SW1t4j4kiSpcxR1QeeVwL9SKVb+D/BT4JqCYkuSpA5SVHHx\nVGZ+CriJyj0p/gA4vaDYkiSpgxRVXDwdEc8HEjgpMweBIwuKLUmSOkhRxcXfAF8Avgr8XkTcBdxe\nUGxJktRBGrqgMyKOAf4eeCGwhsqFnC+hcuOrHzacnSRJ6jiNflrkU8D3qGy5/mrgf2XmRcAPGk1M\nkiR1pkaLi7mZuRIgIm4E7mg8JUmS1Mkavebi2d1fZOZzQ9uSJOnQVPR+4oMFx5MkSR2m0dMiJ0TE\nhiHtudX2BGAwM72XtiRJh5hGi4vjC8limIiYDHwS6AWmAH+VmV9txliSJKlYDRUXmbmxqESGeR3w\naGb+XkQ8j8qFok0vLh54oI+16x9h06P9zJ3RxbLFs1jQ41bT7eZx2V+9r8lDD/fxnbv39l+xeBbH\njNL/F0/vZPWaDWza1s/8GV2ct2IRU6ce+O3iie3PcMO6jXtir1yykO7uw0eM/fgTT3Hj7Q/u6X/O\n4vkc3XPEiP2f3PEc1337PjY92s+8GV2cu/xYpk07bMT+zVbvzysdioracr1oXwT+ufr1ROC5Vgy6\ndv0jXH3tPXsfGIQFZx/a/4iVgcdlf/W+Jt+5e//+F47Sf/WaDVy9em//AeDCsw68UHnDuo0HiD3y\nouaNtz9YV//rvn3fPv0Hx+jfbPX+vNKhqJTFRXXLdSLiKCpFxp+1YtxNj/aP2lZ7eFz2V+9rUnf/\nbf2jtluaS8mOf9nykcqo6E+LFCYi5gP/D/h0Zn6hFWPOndG1b3t61wg91Uoel/3V+5rU23/+8P4z\nRu7f7Fzmlez4Ox+lsZVy5SIiZgFfB96Wmd9s1bjLFs+CwcpfInOnd7FsyaxWDa1ReFz2V+9rsmJY\n/xVj9D9vxSIGqKxYzJ3RxQUrRv7g18olC/eJvXLpwlFjn7N4/j79z1kyf9T+5y4/lsEh/c87+dhR\n+zdbvT+vdCgqZXEBXAIcDfx5RLyXyv0zXp6ZzzRz0AU9PYf8ufwy8rjsr97X5JienlGvsRhu6tTJ\nI15jMVx39+F1XXNwdM8RdfWfNu2wUl3TUO/PKx2KSllcZOafAH/S7jwkSVL9SnvNhSRJ6kwWF5Ik\nqVAWF5IkqVAWF5IkqVAWF5IkqVAWF5IkqVAWF5IkqVAWF5IkqVAWF5IkqVAWF5IkqVClLi4iYllE\ntGzjMkmS1LhS7i0CEBEXA68H+tudiyRJql1piwvgZ8Argc+0asAHHuhj7fpHKlspz+hi2eJZLOhx\nN85287jsr97XpN7+T2x/hhvWbdzTf+WShXR3H95wX4DHn3iKG29/cE//cxbP5+ieI2r/4SWVXmmL\ni8y8JiIWtnLMtesf4epr79n7wCBu9V0CHpf91fua1Nv/hnUb9+s/0jbj9fQFuPH2B+vqL6nzlPqa\ni1bb9Gj/qG21h8dlf/W+Js3s3+xcJHWeTiguJrRqoLkzuvZtT+8aoadayeOyv3pfk2b2b3YukjpP\naU+LDDHYqoGWLZ4Fg5W/pOZO72LZklmtGlqj8Ljsr97XpN7+K5cs3Kf/yqUjn6Gspy/AOYvn79P/\nnCXzR+0vqfOUurjIzI3Aya0ab0FPzyF/Lr+MPC77q/c1qbd/d/fhNV8HUU9fgKN7jvAaC+kg1wmn\nRSRJUgexuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYWyuJAkSYUq9X0uJEkHh4GBAdavX19T\n3+OOO45JkyY1OSM1k8WFJKnpnnziUV5/yeeY1jNz1H47+rbymQ+8luOP90ZrncziQpLUEtN6ZtL1\nvLntTkMt4DUXkiSpUKVcuYiICcBHgRcBTwNvyswN7c1KkiTVopTFBfAK4PDMPDkilgGXVx9rqgce\n6GPt+kcquzXO6GLZ4lks6HHDrHbzuOyv3tek3v6bH+nj1jv39j9t8SxmjdD/2Z0DXH/b/Wzcsp3e\nOd2sXNbL5MkuikqHsrIWF6cA1wFk5tqIWNyKQdeuf4Srr71n7wODuBtnCXhc9lfva1Jv/1vv3L//\nhSP0v/62+7nimjv3dh2E809ZNPYPIemgVdY/L7qBviHtnRHR9Fw3Pdo/alvt4XHZX72vSTP7b9yy\nfdS2pENPWVcutgNHDWlPzMyBZg86d0bXvu3pXSP0VCt5XPZX72vSzP69c7r3aS+c3T1CT6lYu3bt\n4t577625v/fPaJ2yFhdrgPOBL0XEScCdY/QvxLLFs2Cw8lfa3OldLFsyqxXDagwel/3V+5rU2/+0\nYf1PG6X/ymW9DA5WViwWzu7mZSf1judHkup277331nTvDPD+Ga1W1uLiGuCciFhTbV/UikEX9PQc\n8ufyy8jjsr96X5N6+8/q6RnxGovhJk+e6DUWahvvnVFOpSwuMnMQeEu785AkSfUr6wWdkiSpQ1lc\nSJKkQllcSJKkQllcSJKkQllcSJKkQllcSJKkQllcSJKkQllcSJKkQllcSJKkQllcSJKkQpW2uIiI\nV0bEP7U7D0mSVJ9S7i0SER8B/j/gjnbnIkmS6lPK4oLKluvXAG9udyKSpEPHrl27uPfee2vuCzBp\n0qSa+h933HFj9q1n/FpjtkNbi4uIeCPwTmAQmFD9/0WZ+c8RcXqNYSYBbNmypTlJ6qB11lln9QIP\nZebOJg3h3NS4dMrcfOLnTzDw82TXMw+P2XfHLx5hx+CUsfv1beW73/1uTbk9+OCD7OjbWlOutcZ9\n8MEH+Z9XrWFq1/PHjNn3yAYOP/Lomvo+3f84/3XVCubPn1/Y+LXG3G3RokU19RtNrXNzwuDgYMOD\nNUO1uHhzZr52jH6nALe0JisdhI7NzPubEdi5qQY5N1VWY87Nsp4Wqcd3gVOBzcCuNueizvNQE2M7\nN9UI56bKasy52fErF5IkqVxKW1xIkqTOVNr7XEiSpM5kcSFJkgplcSFJkgplcSFJkgrVkR9FjYip\nwGeBmcB24A2Z+diwPu8EXk3lxlyrM/MvDxBnAvBR4EXA08CbMnPDkOcvAP4ceA74VGZeOUZeY8V7\nDfCOarw7M/OtjcQb0u8K4LHMvHS0eDXmuAT4m2pzC/C6zHy2gXi/C7wL2EnlNfzYWDlWv28Z8MHM\nPGPY43Udkxri1XVM6hUR3VTmajdwGPDuzLytwZg1zYsG4k8GPgn0AlOAv8rMrxYVf8g4M4HbgbMz\nc32Bcd8D/CaV1/ujmfmpAmNPBj5N5bXZCfxBUbkPnaMRcRxwFTAA/Dgz31bEGCOM+0rgdzLzd+v8\nvsLm4Ui/n3V8fyFzNiImAp8Agspr/0eZefc4c2p4fkfE94C+avO+zPz9ccZp+HciIt4ArKLyb+oR\nVI777MzcfqD+nbpy8RbgR5l5GvAZKv/Y7BERxwKvycyTMnM5sDIifu0AcV4BHJ6ZJwOXAJcPiTG5\n2j4beCnwhxExY4y8Ros3FXg/cHpmngocHRHnjzfekLhvBg70s4035seBVdXX9jpgYYPxPgScCZwC\nvDsiesZKMCIupvILfviwx8dzTEaLN55jUq93Ad/IzJcCFwH/p4CYY86LBr0OeLQ6B14O/H3B8Xcf\ny48BOwqOezqwvPravBSo7daFtTsXmJSZK4C/BC4rIugB5ujlwKWZeTowMSJ+q4hxDjDuR4C/onKH\n5HoVMg9H+v2sU1Fz9gJgMDNPofLvyriObxHzOyIOB8jMM6v/jbewKOR3IjM/nZlnZOaZwPeAt49U\nWEDnFhenUPmHD+BaKv/YDPUA8LIh7cOoVNYjxsnMtcDiIc/9CvDTzNyemc8BtwKn1ZrXAeI9A5yc\nmc9U25NHyKnWeETEcmAJcMUYcWqKGRHHA48B74qIm4DnZ+ZPG8kR+CHwPCqVLlSq3rH8DHjlAR4f\nzzEZLd54jkm9Lmfv8TkMeKqAmGO95o36InsL9olUVnWK9mHgH4Cx7xtdn5XAjyPiX4GvAF8rOP56\nYHL1r/YeYMRVvToNn6Mvyczdd9A80HtcUdZQ+WNtPIqahyP9ftajkDmbmf8G/GG12Qv8fJz5FDG/\nXwQcGRFfj4hvVFd3xqPQ34mIWAz8amb+42j9Sn9aZNj+I1CpsLewd6noSSpLzntk5i7g8er3fwj4\nfmb+7ADhu4fEAdgZERMzc+AAzz1J5c1kNCPGy8xBYFs1p7cDR2bmN8YbLyJmA39B5a+HV48Rp6aY\nwHRgOfBWYAPwtYi4PTNvGmc8gLuoVLn9wL+MVunulpnXRMSBVkzGc0xGjDfOYzKiUfbK+V71eH0G\n+OPxxh9irNe8IZm5AyAijgL+GfizIuLuFhGrgK2ZeUNEjHkqr07TgQXA+cAiKm+mv1xg/H7gWOAn\nwAuq4zTsAHN06EpCTfN8NAXt4zRcIfNwlN/3emIUNmer769XUXlv/Z16v7/A+b0D+FBm/mNEvBC4\nNiKOH8fvedG/E5cA7xurU+mLi8z8JJVzaXtExJeBo6rNo4Anhn9fdUnpk1Qm/0jn0bcPiQMw9Bdj\nO/sWLQccp454u89R/jXwQuC3x4g1VrwLqby5rQbmAEdExE8y8+oGYj4G/Gz3+cGIuI7KXyM3jSde\nRJwInEfl1MovgH+KiFdl5pfHyHG0seo9JqMaxzEZ0YHmanWME4HPUbne4tZGxqgadZ4VISLmA/8C\n/H1mfqHI2FRODw1ExDnAbwBXR8RvZmZtO1CN7jHgnqxsqrQ+Ip6OiOmZ+WgBsaHyD/R1mflnETEX\n+GZE/Npo1yWN09Dj2fA8H2luNqjp87AeRc7ZzFxVvWZiXUT8SmbWs+JY1PxeT2VVh8z8aUQ8RuW9\nflOdcQr7naie1j4+M28eq2+nnhZZQ+XcJ9X/H2gDnq8Ad2TmW6t/oY4aJyJOAu4c8tw9wC9FxNER\nMYXK8vt3as3rAPGgcj3D4Zn5iiFL8eOKl5l/l5lLque/Pgh8robCYqwcNwBdEbF767xTqaw8jDde\nH5Xq+5nqMdhK5RRJrYafBx7PMRktHtR/TOoSEb9KZcn2tZl5fUFhx5pnDYmIWcDXgf+SmZ8uMjZA\nZp5ePXd7BnAH8HsFFRZQOVX2MoCIOAaYRuXNtSiPs/ev9Seo/IHWjP2uvx8Ru0/5vZxybjJW9Dwc\nz3UfVMcvZM5GxOuqFz9C5RTpLvYt9MZU4Px+I9WL66tz+Sgqe8HUq8jfidOAG2vpWPqVixH8A/Dp\niLiFynnz18KeT4j8lMrPdSpwWEScS2UJ8JLqecGhrgHOiYg11fZFUfn0wJGZeWVEvAu4nsqkvzIz\nxzqwI8ajcmrgIuCWiPhmNae/rZ7jqzte1vgpiXpjRsTvA5+PCIBvZ+a1Dcb7OHBrRDwD3EvlCvha\nDcKeT3SM95iMGI/xHZN6XUblQrW/ra6SPJGZjZ5f3u81bzDecJcARwN/HhHvpfK6vLwZxRe1XYNT\ns8z894g4NSLWUZkjo/1xMR4fAT4ZEd+icg3NJXX+VVurPwU+ERGHUSmqv9SEMRpV9Dxs5DgVNWf/\nBfhURNxM5d+RdzQ47xv5mf6xmsstVAqcN45nZajg34mg8kfomNxbRJIkFapTT4tIkqSSsriQJEmF\nsriQJEmFsriQJEmFsriQJEmFsriQJEmF6tT7XBy0IuJ3gPdQOTYTgM9k5ocbjPlmKpvxfLzBON8E\n/iIzv9VIHB18DjBvr87Mv4mIrwFvorK/wUszc797IUTES6ncD2QalRtSraZy/4i23e1RB4/qrcXX\ns/eGgFOo3OXyoswc994fEfEXVN5X3994lgcfi4sSqd497cPAb2TmExExDbi5elvvcW82k5n1bGwm\n1WWUeZuZeX61DxzghkLVO63+E5VdGx+Iym6SX6Zyy/7Cd2PVIWtTZv6H3Y2IuIzK/Grolv8amcVF\nuUyncky6qNzJcUdEvAF4JiLuo7I1+APVjYb+e2aeUV1NeBz4VSpv0rMy8+2wZ9O2Tezd9OhxKveF\nH/78J6hsBX4Clb8c/2dmfqH6xn8l8BJgI5W9TKThxpy31X4vrN758PnA1zLzEiqrFd1U96jIzJ0R\n8Y5qrN2rZfcAy6jc6fSdmXlD6340HaS+BVxQXXF7NzCVys7Nb8rMW4e9r74a+DUqm6ENAN9l786p\ny6p3KD0GuCozx9zQ61DhNRclkpk/orInyoaIWBsRHwQmZ+a97P9X39D2DzPzV6hs7f1b1dtMQ2VH\nv88P6f9/gVcc4Pn/BtyemUuo/EPw3yKiF3g7lWW/E6js5vlLxf20OljUMW97qWyt/WLglIi4IDOf\nAD5AZS+NOyLiI8DczPzxkO+bkpkvAX6Xym3//aNI41a9pfqrqeyN8mbgvMx8MfA/gYuHdN39vvoo\ncDlwdmaeSOUPsN17W82k8p65GLg4Io5szU9RfhYXJZOZb6Wyi+hHq///TkSMtRfF2ur3bqOyUc4Z\nEXFq5aF8ZEjsbcAPDvD82cAfRcQPqFT0R1BZxXgplU23yMqW9WuQDqDGefuVzHy8ujvjF6nMLzLz\nMiq7PX6AygrG6ogYujX9J6r9fgg8DPx6E38UHZzmRsT3q+9xd1Qfew+V0yIvi4j3AauorphV7d6L\najlw6+59jDLzDZn5lepz12bmzsx8DNhGZVVOeFqkVKqbrHVl5hfh/2/v/l2jCMIwjn+PQ9DGSgQL\nGwsfMJUiCv4BFhbaSRQ7BQsLG3uNgq2QRi1EFEVSKoIgwR9gEzQSI6gvFv4HWgSDGIMW7xzsLWsM\nxwqXu+dT7bEzu3Pc3N7MO8O93CFnaWeA0+QMsBdx2FSrWk2cdA+YBH6W47r7Dee7wKmIWCjt2E6G\nBM/SPwBdHeyd2Sj7R7+t+lU57gArkg4C+yLiOjADzEh6AFwDphvqdWuvzdajb88FQIkyzAN3gZfA\nInCuUqT3XF2hkrFV0rZKmXpfHDiz66hx5GK4LANXy+5myvLFHuAtGZqbKOWOrXGNR2Ra3MNkhr+6\nhw3nn5Eb6JC0g/yS7QRmgZOSOqVNhwZ+ZzbK1uq3VUckbZW0GThB9q+vwEVJ1WjERK3uZLnufjLz\nZY8EH0UAAAD1SURBVKsp5m0sNP3o7wZWS+TsOZnavttQ7jVwoEy6IAe+R/9LK0eIBxdDJCJeAFPA\nY0kfgQ/kZ3QZuARMS5oDvlWq/a5d4wfwCpiLiOWGezSdnwK2SHpPPvAvRMQXMsS9VNpxEz/UrcFf\n+m0HuFIr+gl4Arwhl0hmI+IzGY6+JSlK/b3kfp+eXZLmgRvA8ZZTqNt4aOoz74AFSUFGMJbIJb2+\n8mU55DzwVNIi8B24vc57jC2nXDezoeX/VjHbmBy5MLNh5tmP2QbkyIWZmZm1ypELMzMza5UHF2Zm\nZtYqDy7MzMysVR5cmJmZWas8uDAzM7NW/QFgzg1wzws/3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11806b190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(train[['Survived', 'SibSp', 'Parch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Survived     Sex  Age  SibSp  Parch Embarked\n",
       "5         3         0    male  NaN    0.0      0        Q\n",
       "17        2         1    male  NaN    0.0      0        S\n",
       "19        3         1  female  NaN    0.0      0        C\n",
       "26        3         0    male  NaN    0.0      0        C\n",
       "28        3         1  female  NaN    0.0      0        Q\n",
       "29        3         0    male  NaN    0.0      0        S\n",
       "31        1         1  female  NaN    1.0      0        C\n",
       "32        3         1  female  NaN    0.0      0        Q\n",
       "36        3         1    male  NaN    0.0      0        C\n",
       "42        3         0    male  NaN    0.0      0        C\n",
       "45        3         0    male  NaN    0.0      0        S\n",
       "46        3         0    male  NaN    1.0      0        Q\n",
       "47        3         1  female  NaN    0.0      0        Q\n",
       "48        3         0    male  NaN    2.0      0        C\n",
       "55        1         1    male  NaN    0.0      0        S\n",
       "64        1         0    male  NaN    0.0      0        C\n",
       "65        3         1    male  NaN    1.0      1        C\n",
       "76        3         0    male  NaN    0.0      0        S\n",
       "77        3         0    male  NaN    0.0      0        S\n",
       "82        3         1  female  NaN    0.0      0        Q\n",
       "87        3         0    male  NaN    0.0      0        S\n",
       "95        3         0    male  NaN    0.0      0        S\n",
       "101       3         0    male  NaN    0.0      0        S\n",
       "107       3         1    male  NaN    0.0      0        S\n",
       "109       3         1  female  NaN    1.0      0        Q\n",
       "121       3         0    male  NaN    0.0      0        S\n",
       "126       3         0    male  NaN    0.0      0        Q\n",
       "128       3         1  female  NaN    1.0      1        C\n",
       "140       3         0  female  NaN    0.0      2        C\n",
       "154       3         0    male  NaN    0.0      0        S\n",
       "..      ...       ...     ...  ...    ...    ...      ...\n",
       "718       3         0    male  NaN    0.0      0        Q\n",
       "727       3         1  female  NaN    0.0      0        Q\n",
       "732       2         0    male  NaN    0.0      0        S\n",
       "738       3         0    male  NaN    0.0      0        S\n",
       "739       3         0    male  NaN    0.0      0        S\n",
       "740       1         1    male  NaN    0.0      0        S\n",
       "760       3         0    male  NaN    0.0      0        S\n",
       "766       1         0    male  NaN    0.0      0        C\n",
       "768       3         0    male  NaN    1.0      0        Q\n",
       "773       3         0    male  NaN    0.0      0        C\n",
       "776       3         0    male  NaN    0.0      0        Q\n",
       "778       3         0    male  NaN    0.0      0        Q\n",
       "783       3         0    male  NaN    1.0      2        S\n",
       "790       3         0    male  NaN    0.0      0        Q\n",
       "792       3         0  female  NaN    8.0      2        S\n",
       "793       1         0    male  NaN    0.0      0        C\n",
       "815       1         0    male  NaN    0.0      0        S\n",
       "825       3         0    male  NaN    0.0      0        Q\n",
       "826       3         0    male  NaN    0.0      0        S\n",
       "828       3         1    male  NaN    0.0      0        Q\n",
       "832       3         0    male  NaN    0.0      0        C\n",
       "837       3         0    male  NaN    0.0      0        S\n",
       "839       1         1    male  NaN    0.0      0        C\n",
       "846       3         0    male  NaN    8.0      2        S\n",
       "849       1         1  female  NaN    1.0      0        C\n",
       "859       3         0    male  NaN    0.0      0        C\n",
       "863       3         0  female  NaN    8.0      2        S\n",
       "868       3         0    male  NaN    0.0      0        S\n",
       "878       3         0    male  NaN    0.0      0        S\n",
       "888       3         0  female  NaN    1.0      2        S\n",
       "\n",
       "[177 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Data Wrangling\n",
    "<a id=\"wrangling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Dummy Variables for *Sex* \n",
    "<a id='dum'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply a lambda function to convert sex to categorical\n",
    "train.Sex = train.Sex.map(lambda x: 1 if x == 'female' else 0) \n",
    "\n",
    "\n",
    "# Apply a lambda function to convert embarked to either england or not\n",
    "train.Embarked = train.Embarked.map(lambda x: 1 if x == 'S' or x == 'Q' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Brit_Embark'] = train.Embarked\n",
    "del train['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Brit_Embark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived  Sex   Age  SibSp  Parch  Brit_Embark\n",
       "0       3         0    0  22.0    1.0      0            1\n",
       "1       1         1    1  38.0    1.0      0            0\n",
       "2       3         1    1  26.0    0.0      0            1\n",
       "3       1         1    1  35.0    1.0      0            1\n",
       "4       3         0    0  35.0    0.0      0            1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Logistic Regression and Model Validation\n",
    "<a id='log'></a>\n",
    "\n",
    "1. [Define Variables](#def)         \n",
    "2. [Transform Y](#Y)  \n",
    "3. [Logisitic Regression](#logreg)  \n",
    "4. [Coefficients](#coef)  \n",
    "5. [Test Model](#test)              \n",
    "6. [Predict Labels](#predlab)\n",
    "7. [Predict Probabilities](#predprob)\n",
    "8. [Classification Report](#class)\n",
    "9. [Confusion Matrix](#conf)\n",
    "10. [ROC](#roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the variables for the classification analysis\n",
    "<a id='def'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.dropna(axis=0 , how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train[['Pclass', 'Sex', 'Age','SibSp','Parch', 'Brit_Embark']]\n",
    "\n",
    "X_NoAge = train_na[['Pclass', 'Sex','SibSp','Parch', 'Brit_Embark']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform \"Y\" into a 1-Dimensional Array for SciKit-Learn\n",
    "<a id='Y'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train.Survived\n",
    "\n",
    "Y = np.ravel(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conduct the logistic regression\n",
    "<a id='logreg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Examine the coefficients to see our correlations\n",
    "<a id='coef'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Pclass', -1.0424609810996264)\n",
      "(u'Sex', 2.3661694590378048)\n",
      "(u'Age', -0.036096351167136678)\n",
      "(u'SibSp', -0.26907077971571858)\n",
      "(u'Parch', -0.086058129797693214)\n",
      "('Brit_Embark', -0.19336197040656983)\n"
     ]
    }
   ],
   "source": [
    "coefs = zip(             # Zip together\n",
    "    list(X.columns),     # Get names of the columns\n",
    "    list(log.coef_[0]))  # Get names of coefficient respective to the column\n",
    "\n",
    "for coef in coefs:       # iterate through the coefficients\n",
    "    print coef           # print out coefs and their variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above it would appear that the sex of the individual was a major component in whether or not one would survive. Surprisingly there is a very small effect from the age of the individuals, and beaten out even by whether individuals boarded in France. The negative correlation of class does make sense, as higher classes would likely have been closer to the life boats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test the Model by introducing a *Test* or *Validaton* set \n",
    "<a id='test'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809302325581\n"
     ]
    }
   ],
   "source": [
    "score = log.score(x_test, y_test) # take score of test\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Predict the class labels for the *Test* set\n",
    "<a id='predlab'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = log.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Predict the class probabilities for the *Test* set\n",
    "<a id='predprob'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did Not Survive</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.108796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.841568</td>\n",
       "      <td>0.158432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.749648</td>\n",
       "      <td>0.250352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.332317</td>\n",
       "      <td>0.667683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626959</td>\n",
       "      <td>0.373041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Did Not Survive  Survived\n",
       "0         0.891204  0.108796\n",
       "1         0.841568  0.158432\n",
       "2         0.749648  0.250352\n",
       "3         0.332317  0.667683\n",
       "4         0.626959  0.373041"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_probs = pd.DataFrame(log.predict_proba(x_test), \n",
    "             columns=[\"Did Not Survive\", \"Survived\"])\n",
    "\n",
    "titanic_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Check the Classification Report\n",
    "<a id='class'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Did Not Survive       0.85      0.83      0.84       132\n",
      "       Survived       0.74      0.77      0.76        83\n",
      "\n",
      "    avg / total       0.81      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (classification_report, \n",
    "                             confusion_matrix, roc_curve)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names = ['Did Not Survive', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Explination of Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: How appropriate the model is in being 'right' by assigning those who lived to the appropriate category.\n",
    "\n",
    "Recall: How effective the model is in categorizing those who did survive out of all of the actual survivors. \n",
    "\n",
    "f1-Score: The mean of precision and recall.\n",
    "\n",
    "Support: The total number of both properly classified and imporoperly classified occurences are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Check the Confusion Matrix\n",
    "<a id='conf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Perished</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Perished</th>\n",
       "      <td>110</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Survived</th>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Perished  Predicted Survived\n",
       "Actual Perished                 110                  22\n",
       "Actual Survived                  19                  64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "pd.DataFrame(test_cm, columns=['Predicted Perished', 'Predicted Survived'], \n",
    "             index=['Actual Perished', 'Actual Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What does the Confusion Matrix tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows the rates of properly assigned and improperly assigned classifications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Plot the ROC curve\n",
    "<a id='roc'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAJfCAYAAAA6m3HRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDxGnEygVFl4gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c9db1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, titanic_probs.Survived) # Create ROC curve from probability generated from log reg\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr)) # Make dataframe for reference\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(df.fpr, # Set X-axis as false positive rate\n",
    "         df.tpr, # Set Y-axis as true positive rate \n",
    "         'b-')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. What does the ROC curve tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve shows how well the chosen parameters are in the binary classification of survival or death on the titanic in this instance. It goes acroass all of the various thresholds at once, and can show where to optimise for, depending on the desired threshold for Positives (whether all true, or less often, but more probable). An ideal ROC curve would have the line hug the y-axis and then go along parallel to the x-axis, as that would have entirely true positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use GridSearchCV with logistic regression to search for optimal parameters \n",
    "\n",
    "- Use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,1,50),\n",
    "    'solver':['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_grid = GridSearchCV(log, \n",
    "                        logreg_parameters,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.32571e-05,   1.75751e-05,   2.32995e-05,\n",
       "         3.08884e-05,   4.09492e-05,   5.42868e-05,   7.19686e-05,\n",
       "         9.54095e-05,   1.26486e-04,   1.67683e-04,   2.22300e-04,\n",
       "         2.94705e-04,   3.90694e-04,   5.17947e-04,   6.8...6e+00,   4.29193e+00,   5.68987e+00,\n",
       "         7.54312e+00,   1.00000e+01]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the best parameters and best score. Are they better than the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "{'penalty': 'l2', 'C': 0.035564803062231289, 'solver': 'liblinear'} \n",
      "\n",
      "------------------------------ \n",
      "\n",
      "Best Score: \n",
      "0.791316526611\n"
     ]
    }
   ],
   "source": [
    "print \"Best Parameters: \\n\", log_grid.best_params_, '\\n'\n",
    "print \"-\" * 30, \"\\n\"\n",
    "print \"Best Score: \\n\", log_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain the difference between the difference between the L1 (Lasso) and L2 (Ridge) penalties on the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://bit.ly/1XLhUVQ - Quora Resource\n",
    "\n",
    "L1 penalties are capable of yielding sparse models through reducing some coefficients to zero, while L2 is effective at shrinking coefficients, though it does not elimintate any. This is due to the difference in the way that the penalties deal with values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What hypothetical situations are the Ridge and Lasso penalties useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge is useful if there is a very high degree of signal to noise in the data, and is able to remove the noise that is obscuring the data.\n",
    "Lasso is useful if the data is not complete and has many features of colinearity between the various factors involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. [BONUS] Explain how the regularization strength (C) modifies the regression loss function. Why do the Ridge and Lasso penalties have their respective effects on the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a. [BONUS] You decide that you want to minimize false positives. Use the predicted probabilities from the model to set your threshold for labeling the positive class to need at least 90% confidence. How and why does this affect your confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Gridsearch and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform Gridsearch for the same classification problem as above, but use KNeighborsClassifier as your estimator\n",
    "\n",
    "At least have number of neighbors and weights in your parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors' : [3,5,7,9,15], # Go through sets of neighbors\n",
    "    'algorithm' : ['auto', 'ball_tree', 'kd_tree','brute'], # try various algorithms\n",
    "    'p' : [1, 2] # Try manhattan and euclidean distances\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the best parameters and score for the gridsearched kNN model. How does it compare to the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_Grid = GridSearchCV(knn, knn_params, cv = 5) # Put in GridSearch with 5-fold cv and the params to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 5, 7, 9, 15], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_Grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "{'n_neighbors': 9, 'algorithm': 'brute', 'p': 1} \n",
      "\n",
      "------------------------------ \n",
      "\n",
      "Best Score: \n",
      "0.791316526611\n"
     ]
    }
   ],
   "source": [
    "print \"Best Parameters: \\n\", knn_Grid.best_params_, '\\n'\n",
    "print \"-\" * 30, \"\\n\"\n",
    "print \"Best Score: \\n\", knn_Grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How does the number of neighbors affect the bias-variance tradeoff of your model?\n",
    "The more neighbors there are the more bias the model exhibits, while less neighbors contributes to higher variance.  \n",
    "\n",
    "#### [BONUS] Why?\n",
    "\n",
    "By nature of the classifcation structure of the KNearestNeighbors, the fewer neighbors that are involved in classification, the more clusters there are in 'ambiguous' areas. When the alternative is true, and many neighbors are used, the majority overwhelms those items that may be nearer to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', 'Brit_Embark']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns) ['Pclass', 'Sex', 'Age','SibSp','Parch', 'Brit_Embark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', 'Brit_Embark']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns) ['Pclass', 'Sex', 'Age','SibSp','Parch', 'Brit_Embark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In what hypothetical scenario(s) might you prefer logistic regression over kNN, aside from model performance metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In scenarios where there is a great deal of variables, the use of KNN would become quite confusing, in that the clustering would take place in multi dimensional space. This works in up to three dimensions but when going into higher dimensionality it becomes difficult.  \n",
    "Additionally any scenario that requires a deeper look into the probabilities of assignment logrithmic regression is much more useful. KNN does not calculate the individual probabilities, only assigns the label depending on how the nearest points vote.   \n",
    "Additionally in cases that have an overwelming majority of one case versus another, a logisitic regression would be a much better way of classifying the cases instead of losing resolution through use of KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a new kNN model with the optimal parameters found in gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute', 'n_neighbors': 9, 'p': 1}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_Grid.best_params_ # Determine best parameters from KNN grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set according to best parameters\n",
    "knn2 = KNeighborsClassifier(n_neighbors=9,     # 9 neighbors\n",
    "                            algorithm='brute', # Brute force algorithm\n",
    "                            p=1,               # Manhattan Distance\n",
    "                            weights='uniform') # All points weighted equally in voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=1,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2.fit(X_train, Y_train)  # Fit on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_pred = knn2.predict(x_test) # Predict on test x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Construct the confusion matrix for the optimal kNN model. Is it different from the logistic regression model? If so, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Perished</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Perished</th>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Survived</th>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Perished  Predicted Survived\n",
       "Actual Perished                 120                  12\n",
       "Actual Survived                  32                  51"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_conf = confusion_matrix(y_test, knn_pred) # Compare true y to predicted y\n",
    "pd.DataFrame(knn_conf, columns=['Predicted Perished', 'Predicted Survived'], \n",
    "             index=['Actual Perished', 'Actual Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is different from the Logistic regression in that it predicted fewer survivors and that more people died in the disaster. This is because there are many more points of people who did not survived, and that weights the classification towards more people not surviving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [BONUS] Plot the ROC curves for the optimized logistic regression model and the optimized kNN model on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: [BONUS] Precision-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch the same parameters for logistic regression but change the scoring function to 'average_precision'\n",
    "\n",
    "`'average_precision'` will optimize parameters for area under the precision-recall curve instead of for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Examine the best parameters and score. Are they different than the logistic regression gridsearch in part 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the confusion matrix. Is it different than when you optimized for the accuracy? If so, why would this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot the precision-recall curve. What does this tell us as opposed to the ROC curve?\n",
    "\n",
    "[See the sklearn plotting example here.](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: [VERY BONUS] Decision trees, ensembles, bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch a decision tree classifier model on the data, searching for optimal depth. Create a new decision tree model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare the performace of the decision tree model to the logistic regression and kNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot all three optimized models' ROC curves on the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use sklearn's BaggingClassifier with the base estimator your optimized decision tree model. How does the performance compare to the single decision tree classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gridsearch the optimal n_estimators, max_samples, and max_features for the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create a bagging classifier model with the optimal parameters and compare it's performance to the other two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
